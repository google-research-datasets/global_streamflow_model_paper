{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzNFopjta4Ln"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4538,
     "status": "ok",
     "timestamp": 1686657068813,
     "user": {
      "displayName": "Grey Nearing",
      "userId": "00389065855797486266"
     },
     "user_tz": -180
    },
    "id": "2mIv77EiNGS3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5599,
     "status": "ok",
     "timestamp": 1686657075040,
     "user": {
      "displayName": "Grey Nearing",
      "userId": "00389065855797486266"
     },
     "user_tz": -180
    },
    "id": "NKOTbNQx04-D"
   },
   "outputs": [],
   "source": [
    "from backend import data_paths\n",
    "from backend import evaluation_utils\n",
    "from backend import gauge_groups_utils\n",
    "from backend import loading_utils\n",
    "from backend import skill_prediction_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Basin Attributes for Latitude & Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5678 gauges.\n"
     ]
    }
   ],
   "source": [
    "gauges = gauge_groups_utils.get_full_gauge_group()\n",
    "print(f'There are {len(gauges)} gauges.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = loading_utils.load_attributes_file(gauges=gauges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DH4JNSQM7lD"
   },
   "source": [
    "# Load Return Period Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1686657081409,
     "user": {
      "displayName": "Grey Nearing",
      "userId": "00389065855797486266"
     },
     "user_tz": -180
    },
    "id": "r-Ipfs2Z_YWv"
   },
   "outputs": [],
   "source": [
    "_DATASET_RETURN_PERIOD_METRICS_PATH = {\n",
    "    'google_2014': data_paths.GOOGLE_2014_RETURN_PERIOD_METRICS_DIR,\n",
    "    'google_1980': data_paths.GOOGLE_1980_RETURN_PERIOD_METRICS_DIR,\n",
    "    'glofas_2014': data_paths.GLOFAS_2014_RETURN_PERIOD_METRICS_DIR,\n",
    "    'glofas_1980': data_paths.GLOFAS_1980_RETURN_PERIOD_METRICS_DIR,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6111,
     "status": "ok",
     "timestamp": 1686657097555,
     "user": {
      "displayName": "Grey Nearing",
      "userId": "00389065855797486266"
     },
     "user_tz": -180
    },
    "id": "7O3Y21AUxPxS",
    "outputId": "127befc9-bb5c-480c-d1e9-62a6e8ba9a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on google_2014 ...\n",
      "Finished loading google_2014. \n",
      "\n",
      "Working on google_1980 ...\n",
      "Finished loading google_1980. \n",
      "\n",
      "Working on glofas_2014 ...\n",
      "Finished loading glofas_2014. \n",
      "\n",
      "Working on glofas_1980 ...\n",
      "Finished loading glofas_1980. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "precisions_by_lead_time = {}\n",
    "recalls_by_lead_time = {}\n",
    "\n",
    "precisions_by_return_period = {}\n",
    "recalls_by_return_period = {}\n",
    "\n",
    "for dataset, data_path in _DATASET_RETURN_PERIOD_METRICS_PATH.items():\n",
    "    print(f'Working on {dataset} ...')\n",
    "    file_path = data_paths.CONCATENATED_RETURN_PERIOD_DICTS_DIR / f'{dataset}_return_period_dicts.pkl'\n",
    "    with open(file_path, 'rb') as f:\n",
    "        precisions_by_lead_time[dataset], recalls_by_lead_time[dataset] = pkl.load(f)\n",
    "    print(f'Finished loading {dataset}. \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate F1 Scores from Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1686657100636,
     "user": {
      "displayName": "Grey Nearing",
      "userId": "00389065855797486266"
     },
     "user_tz": -180
    },
    "id": "5gE4-QHOCwSC"
   },
   "outputs": [],
   "source": [
    "f1s_by_lead_time = {\n",
    "    dataset: {\n",
    "        experiment: {\n",
    "            lead_time:\n",
    "              evaluation_utils.f1_from_precision_and_recall_dfs(\n",
    "                  precision_df=precisions_by_lead_time[dataset][experiment][lead_time],\n",
    "                  recall_df=recalls_by_lead_time[dataset][experiment][lead_time]\n",
    "              ) for lead_time in data_paths.LEAD_TIMES\n",
    "        } for experiment in precisions_by_lead_time[dataset]\n",
    "    } for dataset in _DATASET_RETURN_PERIOD_METRICS_PATH\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBieOzakDzvz"
   },
   "source": [
    "# Skill Predictability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Basin Attributes as Classifier/Regression Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1686133666250,
     "user": {
      "displayName": "Grey Nearing",
      "userId": "00389065855797486266"
     },
     "user_tz": -180
    },
    "id": "beH2_oGURQhr",
    "outputId": "2fe10216-2d4e-48aa-9b64-0b2f95ad20f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_208925/1900861654.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  regression_attributes.rename(columns=ATTRIBUTE_DESCRIPTIVE_NAMES, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# A subset of attributes to use as predictor values. This selection is mostly\n",
    "# due to challenges in naming all the HydroATLAS variables, and the skill\n",
    "# is not affected by removing some of the landcover class variables.\n",
    "ATTRIBUTE_DESCRIPTIVE_NAMES = {\n",
    "    'calculated_drain_area': 'Drain Area',\n",
    "    'inu_pc_umn': 'Inundation Percent Min',\n",
    "    'inu_pc_umx': 'Inundation Percent Max',\n",
    "    # 'inu_pc_ult': 'Inundation Percent Long Term Maximum',\n",
    "    'lka_pc_use': 'Precent Lake Area',\n",
    "    'lkv_mc_usu': 'Lake Volume',\n",
    "    'rev_mc_usu': 'Reservoir Volume',\n",
    "    'ria_ha_usu': 'River Area',\n",
    "    'riv_tc_usu': 'River Volume',\n",
    "    'ele_mt_uav': 'Elevation',\n",
    "    'slp_dg_uav': 'Slope',\n",
    "    'tmp_dc_uyr': 'Air Temperature',\n",
    "    'pre_mm_uyr': 'Precipitation',\n",
    "    'pet_mm_uyr': 'PET',\n",
    "    'aet_mm_uyr': 'AET',\n",
    "    'ari_ix_uav': 'Aridity Index',\n",
    "    'cmi_ix_uyr': 'Climate Moisture Index',\n",
    "    'snw_pc_uyr': 'Snow Cover Extent',\n",
    "    'for_pc_use': 'Forest Cover Extent',\n",
    "    'crp_pc_use': 'Cropland Extent',\n",
    "    'pst_pc_use': 'Pastiure Extent',\n",
    "    'ire_pc_use': 'Irrigated Area Extent',\n",
    "    'gla_pc_use': 'Glacier Extent',\n",
    "    'prm_pc_use': 'Permafrost Extent',\n",
    "    'pac_pc_use': 'Protected Area Extent',\n",
    "    'cly_pc_uav': 'Soil Clay Fraction',\n",
    "    'slt_pc_uav': 'Soil Silt Fraction',\n",
    "    'snd_pc_uav': 'Soil Sand Fraction',\n",
    "    'soc_th_uav': 'Soil Organic Carbon',\n",
    "    'swc_pc_uyr': 'Soil Water Content',\n",
    "    'kar_pc_use': 'Karst Area Extent',\n",
    "    'ero_kh_uav': 'Soil Erosion',\n",
    "    'pop_ct_usu': 'Population Count',\n",
    "    'ppd_pk_uav': 'Population Density',\n",
    "    'urb_pc_use': 'Urban Area Extent',\n",
    "    'nli_ix_uav': 'Nighttime Lights Index',\n",
    "    # 'rdd_mk_uav': 'Road Density',\n",
    "    # 'hft_ix_u93': 'Human Footprint 1993',\n",
    "    # 'hft_ix_u09': 'Human Footprint 2009',\n",
    "    'gdp_ud_usu': 'GDP',\n",
    "    # 'latitude': 'latitude',\n",
    "    # 'longitude': 'longitude',\n",
    "}\n",
    "\n",
    "# Select the subset of attributes.\n",
    "regression_attributes = attributes[ATTRIBUTE_DESCRIPTIVE_NAMES.keys()]\n",
    "regression_attributes.rename(columns=ATTRIBUTE_DESCRIPTIVE_NAMES, inplace=True)\n",
    "\n",
    "# Normalize the attributes.\n",
    "regression_attributes = (regression_attributes - regression_attributes.mean()) / regression_attributes.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters for Reliability Score Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "H3_VhHwlG9l2"
   },
   "outputs": [],
   "source": [
    "# Hyperparamters for reliability score predictions.\n",
    "lead_time = 0\n",
    "return_period = 5\n",
    "metric='F1 Score'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Regression Models to Predict Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VywVFlYZKk9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 36 predictors.\n",
      "There are 4699 samples.\n"
     ]
    }
   ],
   "source": [
    "dataset = 'google_1980'\n",
    "experiment = 'kfold_splits'\n",
    "regression_data = f1s_by_lead_time[dataset][experiment][lead_time][return_period].rename(metric)\n",
    "bins = None #[-0.1, regression_data.mean(), 1.01]\n",
    "\n",
    "x, y = skill_prediction_utils.make_predictors(\n",
    "    x=regression_attributes,\n",
    "    y=regression_data,\n",
    "    metric=metric,\n",
    "    bins=bins\n",
    ")\n",
    "\n",
    "model_google = RandomForestRegressor(n_estimators=skill_prediction_utils.N_TREES, random_state=42)\n",
    "model_google = model_google.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46RQVsqXwwJu"
   },
   "source": [
    "## Precidt Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HydroATLAS basin attributes.\n",
    "hydroatlas_attributes = loading_utils.load_full_hydroatlas_attributes_file()\n",
    "hydroatlas_latlon = hydroatlas_attributes[['latitude', 'longitude']]\n",
    "hydroatlas_attributes = hydroatlas_attributes.rename(columns=ATTRIBUTE_DESCRIPTIVE_NAMES)\n",
    "hydroatlas_attributes = hydroatlas_attributes[ATTRIBUTE_DESCRIPTIVE_NAMES.values()]\n",
    "hydroatlas_attributes.dropna(inplace=True)\n",
    "hybas_gauges = list(hydroatlas_attributes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFHtpszbwyZM"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "hydroatlas_attributes = (\n",
    "    hydroatlas_attributes - hydroatlas_attributes.mean()) / hydroatlas_attributes.std()\n",
    "for col in hydroatlas_attributes.columns:\n",
    "    hydroatlas_attributes[col] = hydroatlas_attributes[col].replace(\n",
    "        np.nan, hydroatlas_attributes[col].min())\n",
    "\n",
    "predictions = model_google.predict(hydroatlas_attributes)\n",
    "predictions = pd.Series(\n",
    "    data=predictions, \n",
    "    index=hydroatlas_attributes.index, \n",
    "    name='Predicted F1 Score'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Predicted Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    1, 1, \n",
    "    figsize=(\n",
    "        evaluation_utils.NATURE_FIG_SIZES['one_half_column'], \n",
    "        evaluation_utils.LATITIDE_FIG_SCALER * evaluation_utils.NATURE_FIG_SIZES['one_half_column']\n",
    "    )\n",
    ")\n",
    "\n",
    "ax = evaluation_utils.spatial_plot(\n",
    "    metric_data=predictions,\n",
    "    latlon=hydroatlas_latlon,\n",
    "    metric='Predicted F1 Score',\n",
    "    title=f'Predicted {return_period}-Year Return Period F1 Score',\n",
    "    vmin=0,\n",
    "    vmax=0.5,\n",
    "    ax=axes,\n",
    "    ms=0.1,\n",
    ")\n",
    "\n",
    "evaluation_utils.save_figure(data_paths.GLOBAL_PREDICTED_SKILL_MAP_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//intelligence/flood_forecasting/colab:notebook",
    "kind": "private"
   },
   "provenance": [
    {
     "file_id": "1U5lV5oB6crQAV7-OLTxegU4Dathhwd8Q",
     "timestamp": 1678011930641
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
